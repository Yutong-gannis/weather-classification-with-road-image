{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet_pytorch\nimport numpy as np\nimport pandas as pd\nimport os\nimport json\nimport random\nimport glob\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset\nfrom efficientnet_pytorch import EfficientNet\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensorV2\n\nrandom_state = 42\n\nrandom.seed(random_state)\nnp.random.seed(random_state)\ntorch.manual_seed(random_state)\ntorch.cuda.manual_seed(random_state)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-09T12:45:24.413542Z","iopub.execute_input":"2023-02-09T12:45:24.413862Z","iopub.status.idle":"2023-02-09T12:45:31.845499Z","shell.execute_reply.started":"2023-02-09T12:45:24.413828Z","shell.execute_reply":"2023-02-09T12:45:31.844628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I wanted to predict something using model with multiple outputs. This is a good dataset for this task.","metadata":{}},{"cell_type":"code","source":"root = '/kaggle/input/weathertime-classification-with-road-images'\n\nannotation = open(os.path.join(root,'train_dataset', 'train.json'))\ndata = json.load(annotation)\nprint('Total:', len(data['annotations']))","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:31.848259Z","iopub.execute_input":"2023-02-09T12:45:31.848763Z","iopub.status.idle":"2023-02-09T12:45:31.867507Z","shell.execute_reply.started":"2023-02-09T12:45:31.848718Z","shell.execute_reply":"2023-02-09T12:45:31.866726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = pd.json_normalize(data['annotations'])\ntrain_ds.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:31.868861Z","iopub.execute_input":"2023-02-09T12:45:31.869362Z","iopub.status.idle":"2023-02-09T12:45:31.892370Z","shell.execute_reply.started":"2023-02-09T12:45:31.869326Z","shell.execute_reply":"2023-02-09T12:45:31.891512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#period_encoder = LabelEncoder().fit(train_ds['period'])\nweather_encoder = LabelEncoder().fit(train_ds['weather'])\n\n#train_ds['period'] = period_encoder.transform(train_ds['period'])\ntrain_ds['weather'] = weather_encoder.transform(train_ds['weather'])\ntrain_ds['filename'] = train_ds['filename'].str.replace('\\\\', '/', regex=True)\n\n#print(train_ds['period'].value_counts())\nprint(train_ds['weather'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:31.893902Z","iopub.execute_input":"2023-02-09T12:45:31.894155Z","iopub.status.idle":"2023-02-09T12:45:31.904041Z","shell.execute_reply.started":"2023-02-09T12:45:31.894122Z","shell.execute_reply":"2023-02-09T12:45:31.903324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(train_ds['filename'].values, train_ds['weather'].values, \n                                                    shuffle=True, \n                                                    random_state=random_state, \n                                                    stratify=train_ds['weather'])","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:31.906393Z","iopub.execute_input":"2023-02-09T12:45:31.913469Z","iopub.status.idle":"2023-02-09T12:45:31.926368Z","shell.execute_reply.started":"2023-02-09T12:45:31.913429Z","shell.execute_reply":"2023-02-09T12:45:31.925146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = {\n    x: Compose([\n        Resize(224, 224),\n        ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=0, p=0.2, border_mode=cv2.BORDER_REPLICATE),\n        RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n        OneOf([\n            GaussianBlur(),\n            GaussNoise(),\n        ], p=0.2),\n\n        Normalize(),\n        ToTensorV2()\n    ]) if x == 'train' else Compose([\n        Resize(224, 224),\n        \n        Normalize(),\n        ToTensorV2()\n    ]) for x in ['train', 'test']\n}","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:31.927930Z","iopub.execute_input":"2023-02-09T12:45:31.928566Z","iopub.status.idle":"2023-02-09T12:45:31.940203Z","shell.execute_reply.started":"2023-02-09T12:45:31.928521Z","shell.execute_reply":"2023-02-09T12:45:31.939172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, image_files, labels, transform=None):\n        self.image_files=image_files\n        self.labels=labels\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.image_files)\n    \n    def __getitem__(self, i):\n        image = np.array(Image.open(os.path.join(root, 'train_dataset', self.image_files[i])).convert('RGB'))\n        labels = self.labels[i]\n        \n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        \n        return image, labels","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:31.941539Z","iopub.execute_input":"2023-02-09T12:45:31.942347Z","iopub.status.idle":"2023-02-09T12:45:31.954346Z","shell.execute_reply.started":"2023-02-09T12:45:31.942312Z","shell.execute_reply":"2023-02-09T12:45:31.953582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sets = {\n    'train': (x_train, y_train), 'test': (x_test, y_test)\n}\ndatasets = {\n    x: CustomDataset(sets[x][0], sets[x][1], transforms[x]) for x in sets.keys() \n}\ndataloaders = {\n    x: DataLoader(datasets[x], batch_size=8, num_workers=2, pin_memory=True) for x in sets.keys()\n}","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:31.955283Z","iopub.execute_input":"2023-02-09T12:45:31.956118Z","iopub.status.idle":"2023-02-09T12:45:31.965626Z","shell.execute_reply.started":"2023-02-09T12:45:31.956083Z","shell.execute_reply":"2023-02-09T12:45:31.964740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = EfficientNet.from_pretrained('efficientnet-b0')\nmodel = torchvision.models.mobilenet_v3_small(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:31.966824Z","iopub.execute_input":"2023-02-09T12:45:31.967604Z","iopub.status.idle":"2023-02-09T12:45:32.053865Z","shell.execute_reply.started":"2023-02-09T12:45:31.967570Z","shell.execute_reply":"2023-02-09T12:45:32.053191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = model.to(device)\nlr = 1e-4\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nloss_fn = torch.nn.CrossEntropyLoss().to(device)\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:32.055978Z","iopub.execute_input":"2023-02-09T12:45:32.056491Z","iopub.status.idle":"2023-02-09T12:45:32.074847Z","shell.execute_reply.started":"2023-02-09T12:45:32.056452Z","shell.execute_reply":"2023-02-09T12:45:32.074184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(i, model, data_loader, loss_fn, optimizer, device):\n    overall_loss = 0.\n    \n    with tqdm(data_loader, total=len(data_loader), desc=f'Training, phase {i} :') as loader:\n        for data, weather in loader:\n            optimizer.zero_grad()\n\n            data, weather = data.to(device), weather.to(device)\n            output = model(data)\n            loss = loss_fn(output, weather)\n            \n            overall_loss += loss.item()\n\n            loss.backward()\n            optimizer.step()\n\n            loader.set_postfix(loss=overall_loss / len(data_loader))\n            \n\ndef validation_fn(i, model, data_loader, device):\n    model.eval()\n    \n    weather_accuracy = 0.\n    \n    with tqdm(data_loader, total=len(data_loader), desc=f'Validating, phase {i} :') as loader:\n        with torch.no_grad():\n            for data, weather in loader:\n                data, weather = data.to(device), weather.to(device)\n\n                output = model(data)\n                \n                weather_accuracy += accuracy_score(weather.cpu().detach().numpy(), \n                                                   torch.argmax(output, dim=1).cpu().detach().numpy())\n\n                loader.set_postfix(accuracy_weather=weather_accuracy / len(data_loader))\n    model.train()","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:32.077478Z","iopub.execute_input":"2023-02-09T12:45:32.077668Z","iopub.status.idle":"2023-02-09T12:45:32.085333Z","shell.execute_reply.started":"2023-02-09T12:45:32.077638Z","shell.execute_reply":"2023-02-09T12:45:32.084597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nfor epoch in range(1, epochs + 1):\n    train_fn(epoch, model, dataloaders['train'], loss_fn, optimizer, device)\n    validation_fn(epoch, model, dataloaders['test'], device)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:45:32.086622Z","iopub.execute_input":"2023-02-09T12:45:32.087078Z","iopub.status.idle":"2023-02-09T12:59:19.561554Z","shell.execute_reply.started":"2023-02-09T12:45:32.087043Z","shell.execute_reply":"2023-02-09T12:59:19.560698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nimages = glob.glob(os.path.join(root, 'test_dataset', 'test_images', '*'))\n\nfor _ in range(5):\n    image = np.array(Image.open(np.random.choice(images)).convert('RGB'))\n    print(image.shape)\n    \n    tensor = transforms['test'](image=image)['image'].unsqueeze(0).to(device)\n    print(tensor.shape)\n    output = model(tensor)\n    \n    output = torch.argmax(output, dim=1).cpu().detach().numpy()\n    print(output)\n    plt.imshow(image)\n    plt.title(f'{weather_encoder.inverse_transform(output)[0]}')\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:06:39.994150Z","iopub.execute_input":"2023-02-09T13:06:39.994757Z","iopub.status.idle":"2023-02-09T13:06:41.629778Z","shell.execute_reply.started":"2023-02-09T13:06:39.994717Z","shell.execute_reply":"2023-02-09T13:06:41.629087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = []\nperiod = []\nweather = []\n\nfor file in images:\n    image = np.array(Image.open(file).convert('RGB'))\n    \n    tensor = transforms['test'](image=image)['image'].unsqueeze(0).to(device)\n    output = model(tensor)\n    \n    output = torch.argmax(output, dim=1)\n\n    filename.append(os.path.join(*file.rsplit('/', 2)[1:]).replace('/', '\\\\'))\n    weather.append(output.item())\n\ndf = pd.DataFrame({'filename': filename,  \n                   'weather': weather_encoder.inverse_transform(weather)}\n                 ).sort_values('filename').reset_index(drop=True)\n\ndisplay(df)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:20:19.260731Z","iopub.execute_input":"2023-02-09T13:20:19.261004Z","iopub.status.idle":"2023-02-09T13:20:35.155060Z","shell.execute_reply.started":"2023-02-09T13:20:19.260972Z","shell.execute_reply":"2023-02-09T13:20:35.154321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.to_json(orient='records')\njs_df = {\"root\": {\"annotations\": json.loads(data)}}\nwith open('submission.json', 'w') as out:\n    json.dump(js_df, out, indent=4)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:59:38.360042Z","iopub.execute_input":"2023-02-09T12:59:38.360303Z","iopub.status.idle":"2023-02-09T12:59:38.371380Z","shell.execute_reply.started":"2023-02-09T12:59:38.360253Z","shell.execute_reply":"2023-02-09T12:59:38.370598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PS: I'm not very happy with the results. Might be because datasets are unbalanced. Also, the author said that dataset contains 5 weather classes and 5 period classes, but representation in train set is actually 3 and 4. \n\nI will keep this notebook here as an example. I will be very happy to hear healthy criticism and recommendations. \n\nIf you liked it or found it useful plz UV ;) ","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'mobilenet_v3.pt')","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:01:47.984495Z","iopub.execute_input":"2023-02-09T13:01:47.984798Z","iopub.status.idle":"2023-02-09T13:01:48.039706Z","shell.execute_reply.started":"2023-02-09T13:01:47.984765Z","shell.execute_reply":"2023-02-09T13:01:48.038942Z"},"trusted":true},"execution_count":null,"outputs":[]}]}